{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"../../../assets/Cover.png\" alt=\"WTF-Agents cover\">\n",
    "</div>\n",
    "\n",
    "ä¸Šä¸€èŠ‚ï¼š**[AutoGenæ¡†æ¶ä»‹ç»](../A00-AutoGen_intro/autogen_intro.md)**\n",
    "\n",
    "\n",
    "### ç« èŠ‚ä»‹ç»\n",
    "\n",
    "æœ¬èŠ‚å†…å®¹æˆ‘ä»¬å°†è®²è¿°å¦‚ä½•ä½¿ç”¨AutoGenä»0å¼€å§‹æ„å»ºä¸€ä¸ªæ™ºèƒ½ä½“ï¼Œå†…å®¹åŒ…æ‹¬ç¯å¢ƒçš„æ­å»ºã€æ™ºèƒ½ä½“çš„æ„å»ºä»¥åŠæ ‡å‡†å†…å®¹è¾“å‡ºã€‚\n",
    "\n",
    "æ³¨âš ï¸ï¼šAutoGenä»[v0.2](https://microsoft.github.io/autogen/0.2/) â†’ v0.4ç‰ˆæœ¬è¿›è¡Œäº†ä¸€æ¬¡å½»åº•é‡æ„ï¼Œv0.4é‡‡ç”¨å¼‚æ­¥äº‹ä»¶é©±åŠ¨æ¶æ„ï¼Œæ—¨åœ¨è§£å†³å¯è§‚æµ‹æ€§ã€çµæ´»æ€§ã€äº¤äº’æ§åˆ¶åŠæ‰©å±•æ€§ç­‰é—®é¢˜ï¼Œå¹¶ä¸”ä¸v0.2ä¸å…¼å®¹ã€‚é™¤éå¦å¤–è¯´æ˜ï¼Œæœ¬æ•™ç¨‹çš„å†…å®¹ä»…æŒv0.4åŠä»¥ä¸Šç‰ˆæœ¬ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. ç¯å¢ƒå®‰è£…\n",
    "\n",
    "å‚è€ƒæˆ‘ä»¬åœ¨[Anaconda](../../../basics/00-Anaconda/anaconda.md)ä»‹ç»çš„å…³äºAnacondaçš„å®‰è£…æ–¹æ³•ï¼Œåœ¨ç°æœ‰Anacondaç¯å¢ƒçš„åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬æ­å»ºä¸€ä¸ªè¿è¡ŒAutogençš„åŸºç¡€Pythonç¯å¢ƒï¼Œå–åä¸º`wtf_agents`ã€‚\n",
    "\n",
    "#### åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ\n",
    "\n",
    "1. AutoGenè¦æ±‚ Python 3.10 æˆ–æ›´é«˜ç‰ˆæœ¬ï¼Œå› æ­¤æˆ‘ä»¬åˆ›å»ºä¸€ä¸ª Python 3.12 çš„è™šæ‹Ÿç¯å¢ƒã€‚\n",
    "\n",
    "    ```bash\n",
    "    conda create -n wtf_agents python=3.12 -y\n",
    "    ```\n",
    "\n",
    "2. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒæˆåŠŸåï¼Œæ¿€æ´»è¯¥è™šæ‹Ÿç¯å¢ƒã€‚\n",
    "\n",
    "    ```bash\n",
    "    conda activate wtf_agents\n",
    "    ```\n",
    "\n",
    "3. å®‰è£…AutoGençš„ä¾èµ–åŒ…ã€‚\n",
    "\n",
    "    ```bash\n",
    "    pip install -U \"autogen-agentchat\" \"autogen-ext[openai,azure]\"\n",
    "\n",
    "    ```\n",
    "\n",
    "4. ä¸ºäº†èƒ½èƒ½å¤Ÿæ‰§è¡Œå•å…ƒæ ¼ä»£ç ï¼Œæˆ‘ä»¬éœ€è¦å®‰è£…Jupyter Notebookã€‚\n",
    "\n",
    "    ```bash\n",
    "    pip install jupyter ipykernel\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. åˆ›å»ºè‡ªå·±çš„APIç§é’¥\n",
    "æ¯ä¸€ä¸ªAgentèƒŒåéƒ½ç”±ä¸€ä¸ªLLMï¼ˆLarge Language Modelï¼Œå¤§è¯­è¨€æ¨¡å‹ï¼‰é©±åŠ¨ï¼Œè¿™æ˜¯å®ƒä»¬ä¸ç”¨æˆ·çš„äº¤äº’ä»¥åŠå®ŒæˆæŒ‡å®šä»»åŠ¡çš„åŸºç¡€ã€‚æœ¬æ•™ç¨‹ä¼šé‡‡ç”¨OpenAIã€DeepSeekã€Qwenä¸‰ä¸ªå¹³å°çš„LLMä½œä¸ºæ¼”ç¤ºï¼Œå¤§å®¶å¯ä»¥æ ¹æ®å®é™…ä½¿ç”¨æƒ…å†µé€‰æ‹©é€‚åˆçš„LLMã€‚\n",
    "\n",
    "####  2.1 åˆ›å»ºOpenAI API-Key\n",
    "\n",
    "1. ç™»å½•OpenAIä¸ªäººç§é’¥ç½‘å€ï¼šhttps://platform.openai.com/settings/profile/api-keys\n",
    "2. ç‚¹å‡»å·¦ä¸‹è§’çš„`Create new secret key`æŒ‰é’®ï¼Œåˆ›å»ºä¸€ä¸ªæ–°ç§é’¥ã€‚\n",
    "3. å¤åˆ¶ç”Ÿæˆçš„API Keyï¼Œå¹¶ä¿å­˜åœ¨å®‰å…¨çš„åœ°æ–¹ã€‚\n",
    "\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"./assets/apply_OpenAI_personal_apikey.png\" alt=\"Openai personal apikey\" style=\"width: 60%;\">\n",
    "</div>\n",
    "\n",
    "\n",
    "æˆ–è€…ç”³è¯·ä¸€ä¸ª `project based API keys`\n",
    "\n",
    "\n",
    "1. ç™»å½•OpenAIä¸ªäººç§é’¥ç½‘å€ï¼šhttps://platform.openai.com/settings/organization/api-keys\n",
    "2. ç‚¹å‡»å³ä¸Šè§’çš„`Create new secret key`æŒ‰é’®ï¼Œåˆ›å»ºä¸€ä¸ªæ–°ç§é’¥ã€‚\n",
    "3. å¤åˆ¶ç”Ÿæˆçš„API Keyï¼Œå¹¶ä¿å­˜åœ¨å®‰å…¨çš„åœ°æ–¹ã€‚\n",
    "\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"./assets/apply_OpenAI_project_apikey.png\" alt=\"Openai personal apikey\" style=\"width: 60%;\">\n",
    "</div>\n",
    "\n",
    "\n",
    "####  2.2 åˆ›å»ºDeepSeek API-Key\n",
    "1. ç™»å½•DeepSeek Platformï¼šhttps://platform.deepseek.com/api_keys\n",
    "2. ç‚¹å‡»å³ä¸Šè§’çš„`Create new API key`æŒ‰é’®ï¼Œåˆ›å»ºä¸€ä¸ªæ–°api keyã€‚\n",
    "3. å¤åˆ¶ç”Ÿæˆçš„API Keyï¼Œå¹¶ä¿å­˜åœ¨å®‰å…¨çš„åœ°æ–¹ã€‚\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"./assets/deepseek_apikey.png\" alt=\"Openai personal apikey\" style=\"width: 60%;\">\n",
    "</div>\n",
    "\n",
    "\n",
    "#### 2.3 åˆ›å»ºQwen API-Key\n",
    "1. ç™»å½•é˜¿é‡Œäº‘ç™¾ç‚¼å¹³å°ï¼šhttps://bailian.console.aliyun.com/?tab=model#/api-key\n",
    "2. ç‚¹å‡»å³ä¸Šè§’çš„`åˆ›å»ºæˆ‘çš„API-KEY`æŒ‰é’®ï¼Œåˆ›å»ºä¸€ä¸ªæ–°api keyã€‚\n",
    "3. å¤åˆ¶ç”Ÿæˆçš„API Keyï¼Œå¹¶ä¿å­˜åœ¨å®‰å…¨çš„åœ°æ–¹ã€‚\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"./assets/Qwen_apikey.png\" alt=\"Openai personal apikey\" style=\"width: 60%;\">\n",
    "</div>\n",
    "\n",
    "\n",
    "æ³¨âš ï¸ï¼šéƒ¨åˆ†å¹³å°ç§é’¥åªä¼šåœ¨åˆ›å»ºæ—¶æ˜¾ç¤ºä¸€æ¬¡ï¼Œåç»­æ— æ³•å†æ¬¡æŸ¥çœ‹ï¼Œè¯·å¦¥å–„ä¿ç®¡ã€‚\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### 2.4 å¯¼å‡ºAPI Keyåˆ°é…ç½®æ–‡ä»¶\n",
    "\n",
    "\n",
    "åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œè¯·ä¸è¦å°†API Keyç›´æ¥ç¡¬ç¼–ç åœ¨ä»£ç ä¸­ï¼Œè€Œæ˜¯åº”è¯¥å°†å…¶ä¿å­˜åœ¨ç¯å¢ƒå˜é‡ä¸­ï¼Œå¹¶ä½¿ç”¨`os.getenv()`å‡½æ•°æ¥è·å–ã€‚ä»¥`OPENAI_API_KEY` ä¸ºä¾‹å±•ç¤ºç³»ç»Ÿå˜é‡çš„è®¾ç½®æ–¹æ³•ï¼š\n",
    "\n",
    "\n",
    "**Mac/Linuxç³»ç»Ÿï¼š**\n",
    "\n",
    "ä¸´æ—¶è®¾ç½® (ä»…å¯¹å½“å‰çª—å£æœ‰æ•ˆ)ï¼Œåœ¨ç»ˆç«¯æ‰§è¡Œå‘½ä»¤è¡Œï¼š\n",
    "\n",
    "```bash\n",
    "export OPENAI_API_KEY=\"sk-xxx\"\n",
    "```\n",
    "\n",
    "æŒä¹…è®¾ç½® (å¯¹æ•´ä¸ªç³»ç»Ÿæœ‰æ•ˆ)ï¼Œåœ¨ç»ˆç«¯æ‰§è¡Œå‘½ä»¤è¡Œï¼š\n",
    "\n",
    "```bash\n",
    "echo \"export OPENAI_API_KEY=sk-xxx\" >> ~/.bashrc\n",
    "source ~/.bashrc\n",
    "```\n",
    "\n",
    "**Windowsç³»ç»Ÿï¼š**\n",
    "\n",
    "ä¸´æ—¶è®¾ç½® (ä»…å¯¹å½“å‰çª—å£æœ‰æ•ˆ)ï¼Œåœ¨ç»ˆç«¯æ‰§è¡Œå‘½ä»¤è¡Œ\n",
    "\n",
    "```bash\n",
    "set OPENAI_API_KEY=sk-xxx\n",
    "\n",
    "```\n",
    "\n",
    "æ°¸ä¹…è®¾ç½®\n",
    "\n",
    "```powershell\n",
    " setx OPENAI_API_KEY \"sk-xxx\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. æµ‹è¯•API-Keyæ˜¯å¦ç”Ÿæ•ˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# è¾“å‡º OPENAI_API_KEY  ç¯å¢ƒå˜é‡\n",
    "print(os.getenv(\"OPENAI_API_KEY\"))\n",
    "print(os.getenv(\"Qwen_API_KEY\"))\n",
    "print(os.getenv(\"DeepSeek_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI Api content:  Under a shimmering silver moon, a gentle unicorn named Luna sprinkled stardust across a sleepy meadow, wishing every dreamer a night of magical dreams.\n",
      "Qwen Api content:  æˆ‘æ˜¯é€šä¹‰åƒé—®ï¼Œé˜¿é‡Œå·´å·´é›†å›¢æ——ä¸‹çš„é€šä¹‰å®éªŒå®¤è‡ªä¸»ç ”å‘çš„è¶…å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ã€‚æˆ‘èƒ½å¤Ÿå›ç­”é—®é¢˜ã€åˆ›ä½œæ–‡å­—ï¼Œå¦‚å†™æ•…äº‹ã€å…¬æ–‡ã€é‚®ä»¶ã€å‰§æœ¬ç­‰ï¼Œè¿˜èƒ½è¿›è¡Œé€»è¾‘æ¨ç†ã€ç¼–ç¨‹ç­‰ä»»åŠ¡ã€‚å¦‚æœä½ æœ‰ä»»ä½•é—®é¢˜æˆ–éœ€è¦å¸®åŠ©ï¼Œæ¬¢è¿éšæ—¶å‘Šè¯‰æˆ‘ï¼\n",
      "DeepSeek Api content:  Hello! How can I assist you today? ğŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "# 1. æµ‹è¯• OpenAI API\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4.1\",\n",
    "    input=\"Write a one-sentence bedtime story about a unicorn.\"\n",
    ")\n",
    "\n",
    "print(f\"OpenAI Api content:  {response.output_text}\")\n",
    "\n",
    "\n",
    "\n",
    "# 2. æµ‹è¯• Qwen API\n",
    "client = OpenAI(\n",
    "    # è‹¥æ²¡æœ‰é…ç½®ç¯å¢ƒå˜é‡ï¼Œè¯·ç”¨ç™¾ç‚¼API Keyå°†ä¸‹è¡Œæ›¿æ¢ä¸ºï¼šapi_key=\"sk-xxx\",\n",
    "    api_key=os.getenv(\"Qwen_API_KEY\"),\n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    # æ¨¡å‹åˆ—è¡¨ï¼šhttps://help.aliyun.com/zh/model-studio/getting-started/models\n",
    "    model=\"qwen-plus\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"ä½ æ˜¯è°ï¼Ÿ\"},\n",
    "    ],\n",
    "    # Qwen3æ¨¡å‹é€šè¿‡enable_thinkingå‚æ•°æ§åˆ¶æ€è€ƒè¿‡ç¨‹ï¼ˆå¼€æºç‰ˆé»˜è®¤Trueï¼Œå•†ä¸šç‰ˆé»˜è®¤Falseï¼‰\n",
    "    # ä½¿ç”¨Qwen3å¼€æºç‰ˆæ¨¡å‹æ—¶ï¼Œè‹¥æœªå¯ç”¨æµå¼è¾“å‡ºï¼Œè¯·å°†ä¸‹è¡Œå–æ¶ˆæ³¨é‡Šï¼Œå¦åˆ™ä¼šæŠ¥é”™\n",
    "    # extra_body={\"enable_thinking\": False},\n",
    ")\n",
    "content = completion.choices[0].message.content\n",
    "print(f\"Qwen Api content:  {content}\")\n",
    "\n",
    "# æµ‹è¯•ä½¿ç”¨DeepSeek API\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"DeepSeek_API_KEY\"), \n",
    "                base_url=\"https://api.deepseek.com\"\n",
    "                )\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"deepseek-chat\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "        {\"role\": \"user\", \"content\": \"Hello\"},\n",
    "    ],\n",
    "    stream=False\n",
    ")\n",
    "\n",
    "print(f\"DeepSeek Api content:  {response.choices[0].message.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. æ¥ä¸‹æ¥æˆ‘ä»¬å°†ä¼šåˆ›å»ºè‡ªå·±çš„ç¬¬ä¸€ä¸ªæ™ºèƒ½ä½“ğŸ¤–ï¼Œè®©Taæ¬¢è¿ä½ çš„åˆ°æ¥ï¼\n",
    "\n",
    "#### 4.1 ä½¿ç”¨OpenAI apikeyåˆ›å»ºæ™ºèƒ½ä½“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- TextMessage (user) ----------\n",
      "Hey~ I am Xiaobang\n",
      "---------- ToolCallRequestEvent (Receptionist) ----------\n",
      "[FunctionCall(id='call_XlDI1VHANaLnMLsOeBZgD2tP', arguments='{\"name\":\"Xiaobang\"}', name='hello_world')]\n",
      "---------- ToolCallExecutionEvent (Receptionist) ----------\n",
      "[FunctionExecutionResult(content='Hello Xiaobang~ Welcome to WTF-Agent!', name='hello_world', call_id='call_XlDI1VHANaLnMLsOeBZgD2tP', is_error=False)]\n",
      "---------- ModelClientStreamingChunkEvent (Receptionist) ----------\n",
      "Hey Xiaobang~ Welcome! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient  # autogen_ext æ˜¯ autogen extensionåŒ…ï¼Œæä¾›äº†å¯¹è¯¸å¤šæ¨¡å‹çš„æ”¯æŒã€‚\n",
    "\n",
    "# å®šä¹‰ä¸€ä¸ªæ¨¡å‹å®¢æˆ·ç«¯ã€‚ä¹Ÿå¯ä»¥ä½¿ç”¨å…¶ä»–å®ç°äº† `ChatCompletionClient` æ¥å£çš„æ¨¡å‹å®¢æˆ·ç«¯ã€‚\n",
    "model_client = OpenAIChatCompletionClient(\n",
    "    model=\"gpt-4.1\",\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "# å®šä¹‰ä¸€ä¸ªå·¥å…·å‡½æ•°ï¼Œè®©æ™ºèƒ½ä½“è°ƒç”¨\n",
    "async def hello_world(name: str) -> str:\n",
    "    \"\"\"\n",
    "    A simple tool that returns a greeting message.\n",
    "    :param name: The name of the person to greet.\n",
    "\n",
    "    \"\"\"\n",
    "    return f\"Hello {name}~ Welcome to WTF-Agent!\"\n",
    "\n",
    "\n",
    "# å®šä¹‰ä¸€ä¸ª AssistantAgentï¼Œå¹¶å¯ç”¨æ¨¡å‹ã€å·¥å…·ã€ç³»ç»Ÿæ¶ˆæ¯å’Œåå°„ã€‚\n",
    "agent = AssistantAgent(\n",
    "    name=\"Receptionist\",  # The name of the agent.\n",
    "    model_client=model_client,\n",
    "    tools=[hello_world],\n",
    "    system_message=\"You are a warm receptionist. Please use the tools to help your friends.\",\n",
    "    reflect_on_tool_use=True,\n",
    "    model_client_stream=True,  # Enable streaming tokens from the model client.\n",
    ")\n",
    "\n",
    "\n",
    "# æ‰§è¡Œæ™ºèƒ½ä½“ä»»åŠ¡ï¼Œå¹¶å°†è¾“å‡ºæµå¼ä¼ è¾“åˆ°æ§åˆ¶å°ã€‚\n",
    "async def main() -> None:\n",
    "    await Console(agent.run_stream(task=\"Hey~ I am Xiaobang\"))\n",
    "    # Close the connection to the model client.\n",
    "    await model_client.close()\n",
    "\n",
    "\n",
    "# NOTE: if running this inside a Python script you'll need to use asyncio.run(main()).\n",
    "await main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 ä½¿ç”¨DeepSeekæ¨¡å‹å®ç°ä¸Šè¿°Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- TextMessage (user) ----------\n",
      "Hey~ I am Xiaobang\n",
      "---------- ToolCallRequestEvent (Receptionist) ----------\n",
      "[FunctionCall(id='call_0_58a86283-635b-4dd4-bd59-aad838fcd2fb', arguments='{\"name\":\"Xiaobang\"}', name='hello_world')]\n",
      "---------- ToolCallExecutionEvent (Receptionist) ----------\n",
      "[FunctionExecutionResult(content='Hello Xiaobang~ Welcome to WTF-Agent!', name='hello_world', call_id='call_0_58a86283-635b-4dd4-bd59-aad838fcd2fb', is_error=False)]\n",
      "---------- ModelClientStreamingChunkEvent (Receptionist) ----------\n",
      "Hello Xiaobang~ Welcome to WTF-Agent! How can I assist you today? ğŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_core.models import ModelFamily\n",
    "\n",
    "\n",
    "# åˆ›å»ºæ¨¡å‹å®¢æˆ·ç«¯\n",
    "model_client = OpenAIChatCompletionClient(\n",
    "    model=\"deepseek-chat\",\n",
    "    api_key=os.getenv(\"DeepSeek_API_KEY\"),\n",
    "    base_url=\"https://api.deepseek.com\",\n",
    "    model_info={\n",
    "        \"vision\": False,             # æ˜¯å¦æ”¯æŒå›¾åƒè¾“å…¥\n",
    "        \"function_calling\": True,    # æ˜¯å¦æ”¯æŒå‡½æ•°è°ƒç”¨\n",
    "        \"json_output\": True,         # æ˜¯å¦æ”¯æŒ JSON è¾“å‡º\n",
    "        \"family\": ModelFamily.UNKNOWN,  # ä¹Ÿå¯ä»¥è‡ªå®šä¹‰ä¸º ModelFamily.R1 æˆ–å…¶å®ƒ\n",
    "        \"structured_output\": True    # æ˜¯å¦æ”¯æŒç»“æ„åŒ–è¾“å‡º\n",
    "    }\n",
    ")\n",
    "\n",
    "# å®šä¹‰ä¸€ä¸ªå·¥å…·å‡½æ•°ï¼Œè®©æ™ºèƒ½ä½“è°ƒç”¨\n",
    "async def hello_world(name: str) -> str:\n",
    "    \"\"\"\n",
    "    A simple tool that returns a greeting message.\n",
    "    :param name: The name of the person to greet.\n",
    "\n",
    "    \"\"\"\n",
    "    return f\"Hello {name}~ Welcome to WTF-Agent!\"\n",
    "\n",
    "# å®šä¹‰åŠ©æ‰‹æ™ºèƒ½ä½“\n",
    "agent = AssistantAgent(\n",
    "    name=\"Receptionist\",\n",
    "    model_client=model_client,\n",
    "    tools=[hello_world],\n",
    "    system_message=\"You are a warm receptionist. Please use the tools to help your friends.\",\n",
    "    reflect_on_tool_use=True,\n",
    "    model_client_stream=True,\n",
    ")\n",
    "\n",
    "# è¿è¡Œæ™ºèƒ½ä½“å¹¶å°†æ¶ˆæ¯æµå¼è¾“å‡ºåˆ°æ§åˆ¶å°\n",
    "async def main() -> None:\n",
    "    await Console(agent.run_stream(task=\"Hey~ I am Xiaobang\"))\n",
    "    # å…³é—­ä¸æ¨¡å‹å®¢æˆ·ç«¯çš„è¿æ¥\n",
    "    await model_client.close()\n",
    "\n",
    "# è¿è¡Œä¸»å‡½æ•°\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 æœ€åæ¥æˆ‘ä»¬ç»§ç»­ä½¿ç”¨Qwenæ¨¡å‹å®ç°ä¸Šè¿°Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- TextMessage (user) ----------\n",
      "Hey~ I am Xiaobang\n",
      "---------- ToolCallRequestEvent (Receptionist) ----------\n",
      "[FunctionCall(id='call_243f639647c947c1897ccf', arguments='{\"name\": \"Xiaobang\"}', name='hello_world')]\n",
      "---------- ToolCallExecutionEvent (Receptionist) ----------\n",
      "[FunctionExecutionResult(content='Hello Xiaobang~ Welcome to WTF-Agent!', name='hello_world', call_id='call_243f639647c947c1897ccf', is_error=False)]\n",
      "---------- ModelClientStreamingChunkEvent (Receptionist) ----------\n",
      "Hi Xiaobang! It's so nice to meet you. I can see you're new here. How about I help you get settled? Maybe grab you a cup of coffee or show you around our space? Oh, and if you need any tools or resources, just let me know! How are you finding everything so far?\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_core.models import ModelFamily\n",
    "\n",
    "\n",
    "# åˆ›å»ºæ¨¡å‹å®¢æˆ·ç«¯\n",
    "model_client = OpenAIChatCompletionClient(\n",
    "    model=\"qwen-plus\",\n",
    "    api_key=os.getenv(\"Qwen_API_KEY\"),\n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    "    model_info={\n",
    "        \"vision\": True,             # æ˜¯å¦æ”¯æŒå›¾åƒè¾“å…¥\n",
    "        \"function_calling\": True,    # æ˜¯å¦æ”¯æŒå‡½æ•°è°ƒç”¨\n",
    "        \"json_output\": True,         # æ˜¯å¦æ”¯æŒ JSON è¾“å‡º\n",
    "        \"family\": ModelFamily.UNKNOWN,  # ä¹Ÿå¯ä»¥è‡ªå®šä¹‰ä¸º ModelFamily.R1 æˆ–å…¶å®ƒ\n",
    "        \"structured_output\": True    # æ˜¯å¦æ”¯æŒç»“æ„åŒ–è¾“å‡º\n",
    "    }\n",
    ")\n",
    "\n",
    "# å®šä¹‰ä¸€ä¸ªå·¥å…·å‡½æ•°ï¼Œè®©æ™ºèƒ½ä½“è°ƒç”¨\n",
    "async def hello_world(name: str) -> str:\n",
    "    \"\"\"\n",
    "    A simple tool that returns a greeting message.\n",
    "    :param name: The name of the person to greet.\n",
    "\n",
    "    \"\"\"\n",
    "    return f\"Hello {name}~ Welcome to WTF-Agent!\"\n",
    "\n",
    "# å®šä¹‰åŠ©æ‰‹æ™ºèƒ½ä½“\n",
    "agent = AssistantAgent(\n",
    "    name=\"Receptionist\",\n",
    "    model_client=model_client,\n",
    "    tools=[hello_world],\n",
    "    system_message=\"You are a warm receptionist. Please use the tools to help your friends.\",\n",
    "    reflect_on_tool_use=True,\n",
    "    model_client_stream=True,\n",
    ")\n",
    "\n",
    "# è¿è¡Œæ™ºèƒ½ä½“å¹¶å°†æ¶ˆæ¯æµå¼è¾“å‡ºåˆ°æ§åˆ¶å°\n",
    "async def main() -> None:\n",
    "    await Console(agent.run_stream(task=\"Hey~ I am Xiaobang\"))\n",
    "    # å…³é—­ä¸æ¨¡å‹å®¢æˆ·ç«¯çš„è¿æ¥\n",
    "    await model_client.close()\n",
    "\n",
    "# è¿è¡Œä¸»å‡½æ•°\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. æŸ¥çœ‹AutoGen æ¡†æ¶ç›®å‰å·²ç»æ”¯æŒäº†å“ªäº›LLM\n",
    "\n",
    "æˆ‘ä»¬åœ¨å®šä¹‰æ¨¡å‹å®¢æˆ·ç«¯çš„æ—¶å€™å¯ä»¥çœ‹åˆ° `model_info`ä¸­æœ‰ä¸ª`family`å­—æ®µï¼Œè¿™ä¸ªå­—æ®µè¡¨ç¤ºçš„æ˜¯æ¨¡å‹æ‰€å±çš„LLM,æ¥ä¸‹æ¥æˆ‘ä»¬æŸ¥çœ‹ä¸€ä¸‹AutoGenç›®å‰å·²ç»æ”¯æŒçš„LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelFamily å±æ€§å’Œæ–¹æ³•:\n",
      "æ¨¡å‹å®¶æ—:\n",
      "- GPT_41: gpt-41\n",
      "- GPT_45: gpt-45\n",
      "- GPT_4O: gpt-4o\n",
      "- O1: o1\n",
      "- O3: o3\n",
      "- O4: o4\n",
      "- GPT_4: gpt-4\n",
      "- GPT_35: gpt-35\n",
      "- R1: r1\n",
      "- GEMINI_1_5_FLASH: gemini-1.5-flash\n",
      "- GEMINI_1_5_PRO: gemini-1.5-pro\n",
      "- GEMINI_2_0_FLASH: gemini-2.0-flash\n",
      "- GEMINI_2_5_PRO: gemini-2.5-pro\n",
      "- CLAUDE_3_HAIKU: claude-3-haiku\n",
      "- CLAUDE_3_SONNET: claude-3-sonnet\n",
      "- CLAUDE_3_OPUS: claude-3-opus\n",
      "- CLAUDE_3_5_HAIKU: claude-3-5-haiku\n",
      "- CLAUDE_3_5_SONNET: claude-3-5-sonnet\n",
      "- CLAUDE_3_7_SONNET: claude-3-7-sonnet\n",
      "- CODESRAL: codestral\n",
      "- OPEN_CODESRAL_MAMBA: open-codestral-mamba\n",
      "- MISTRAL: mistral\n",
      "- MINISTRAL: ministral\n",
      "- PIXTRAL: pixtral\n",
      "- UNKNOWN: unknown\n",
      "- ANY: typing.Literal['gpt-41', 'gpt-45', 'gpt-4o', 'o1', 'o3', 'o4', 'gpt-4', 'gpt-35', 'r1', 'gemini-1.5-flash', 'gemini-1.5-pro', 'gemini-2.0-flash', 'gemini-2.5-pro', 'claude-3-haiku', 'claude-3-sonnet', 'claude-3-opus', 'claude-3-5-haiku', 'claude-3-5-sonnet', 'claude-3-7-sonnet', 'codestral', 'open-codestral-mamba', 'mistral', 'ministral', 'pixtral', 'unknown']\n",
      "- is_claude: <staticmethod(<function ModelFamily.is_claude at 0x000001BBF73BEE60>)>\n",
      "- is_gemini: <staticmethod(<function ModelFamily.is_gemini at 0x000001BBF73BF010>)>\n",
      "- is_openai: <staticmethod(<function ModelFamily.is_openai at 0x000001BBF73BEF80>)>\n",
      "- is_mistral: <staticmethod(<function ModelFamily.is_mistral at 0x000001BBF73BFAC0>)>\n"
     ]
    }
   ],
   "source": [
    "# å¯¼å‡º ModelFamily ç±»\n",
    "from autogen_core.models import ModelFamily\n",
    "\n",
    "print(\"\\nModelFamily å±æ€§å’Œæ–¹æ³•:\")\n",
    "try:\n",
    "    model_families = {name: value for name, value in vars(ModelFamily).items() \n",
    "                        if not name.startswith('__')}\n",
    "    if model_families:\n",
    "        print(\"æ¨¡å‹å®¶æ—:\")\n",
    "        for name, value in model_families.items():\n",
    "            print(f\"- {name}: {value}\")\n",
    "    else:\n",
    "        print(\"æœªæ‰¾åˆ°æ¨¡å‹å®¶æ—å®šä¹‰\")\n",
    "except Exception as e:\n",
    "    print(f\"è·å–ç±»å˜é‡å¤±è´¥: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç›®å‰ï¼ˆAutoGen v0.5.7 stable ç‰ˆæœ¬ï¼‰AutoGenæ”¯æŒçš„LLMä¿¡æ¯åŒ…æ‹¬ï¼š\n",
    "\n",
    "> ModelFamily å±æ€§å’Œæ–¹æ³•:\n",
    ">\n",
    "> æ¨¡å‹å®¶æ—:\n",
    "> - GPT_41: gpt-41\n",
    "> - GPT_45: gpt-45\n",
    "> - GPT_4O: gpt-4o\n",
    "> - O1: o1\n",
    "> - O3: o3\n",
    "> - O4: o4\n",
    "> - GPT_4: gpt-4\n",
    "> - GPT_35: gpt-35\n",
    "> - R1: r1\n",
    "> - GEMINI_1_5_FLASH: gemini-1.5-flash\n",
    "> - GEMINI_1_5_PRO: gemini-1.5-pro\n",
    "> - GEMINI_2_0_FLASH: gemini-2.0-flash\n",
    "> - GEMINI_2_5_PRO: gemini-2.5-pro\n",
    "> - CLAUDE_3_HAIKU: claude-3-haiku\n",
    "> - CLAUDE_3_SONNET: claude-3-sonnet\n",
    "> - CLAUDE_3_OPUS: claude-3-opus\n",
    "> - CLAUDE_3_5_HAIKU: claude-3-5-haiku\n",
    "> - CLAUDE_3_5_SONNET: claude-3-5-sonnet\n",
    "> - CLAUDE_3_7_SONNET: claude-3-7-sonnet\n",
    "> - CODESRAL: codestral\n",
    "> - OPEN_CODESRAL_MAMBA: open-codestral-mamba\n",
    "> - MISTRAL: mistral\n",
    "> - MINISTRAL: ministral\n",
    "> - PIXTRAL: pixtral\n",
    "> - UNKNOWN: unknown\n",
    "> - ANY: typing.Literal['gpt-41', 'gpt-45', 'gpt-4o', 'o1', 'o3', 'o4', 'gpt-4', 'gpt-35', 'r1', 'gemini-1.5-flash', 'gemini-1.5-pro', 'gemini-2.0-flash', 'gemini-2.5-pro', 'claude-3-haiku', 'claude-3-sonnet', 'claude-3-opus', 'claude-3-5-haiku', 'claude-3-5-sonnet', 'claude-3-7-sonnet', 'codestral', 'open-codestral-mamba', 'mistral', 'ministral', 'pixtral', 'unknown']\n",
    "> - is_claude: <staticmethod(<function ModelFamily.is_claude at 0x000001BBF73BEE60>)>\n",
    "> - is_gemini: <staticmethod(<function ModelFamily.is_gemini at 0x000001BBF73BF010>)>\n",
    "> - is_openai: <staticmethod(<function ModelFamily.is_openai at 0x000001BBF73BEF80>)>\n",
    "> - is_mistral: <staticmethod(<function ModelFamily.is_mistral at 0x000001BBF73BFAC0>)>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. æ€»ç»“\n",
    "åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å­¦ä¹ äº†å¦‚ä½•ä½¿ç”¨ AutoGen ä»é›¶å¼€å§‹æ„å»ºä¸€ä¸ªç®€å•çš„æ™ºèƒ½ä½“ğŸ‰ã€‚æˆ‘ä»¬äº†è§£äº†ç¯å¢ƒæ­å»ºã€API å¯†é’¥çš„è·å–ä¸é…ç½®ï¼Œä»¥åŠå¦‚ä½•ä½¿ç”¨ OpenAIã€DeepSeek å’Œ Qwen ç­‰ä¸åŒå¹³å°çš„ LLM æ¥é©±åŠ¨æ™ºèƒ½ä½“ã€‚æˆ‘ä»¬è¿˜å­¦ä¹ äº†å¦‚ä½•å®šä¹‰å·¥å…·å‡½æ•°ï¼Œå¹¶å°†å…¶èµ‹äºˆæ™ºèƒ½ä½“ä½¿ç”¨ï¼Œä»¥åŠå¦‚ä½•é€šè¿‡æµå¼è¾“å‡ºå°†æ™ºèƒ½ä½“çš„å“åº”å±•ç¤ºåœ¨æ§åˆ¶å°ä¸Šã€‚é€šè¿‡æœ¬èŠ‚çš„å­¦ä¹ ï¼Œæˆ‘ä»¬å·²ç»æŒæ¡äº†æ„å»ºå•ä¸ªæ™ºèƒ½ä½“çš„åŸºæœ¬æŠ€èƒ½ã€‚\n",
    "\n",
    "ä¸‹ä¸€èŠ‚ï¼š**[Messages-æ™ºèƒ½ä½“ä¿¡æ¯ä¼ é€’](../A02-Messages/Messages.ipynb)**\n",
    "\n",
    "`Message` æ˜¯AutoGenæ¡†æ¶ä¸­ä¸€ä¸ªå¾ˆåŸºç¡€ä½†åˆå¾ˆé‡è¦çš„æ¨¡å—ï¼Œå¤šæ™ºèƒ½ä¹‹é—´çš„ä¿¡æ¯ä¼ é€’ä»¥åŠæ™ºèƒ½ä½“å†…éƒ¨äº‹ä»¶çŠ¶æ€çš„è·å–éƒ½éœ€è¦ä¾èµ– `Message` æ¨¡å—ï¼ŒæŒæ¡ `Message` æ¨¡å—çš„åŸºç¡€çŸ¥è¯†ï¼Œæ‰èƒ½æ›´å¥½çš„ç†è§£AutoGenæ¡†æ¶çš„è¿è¡Œæœºåˆ¶ã€‚\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
